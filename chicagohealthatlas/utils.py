# -*- coding: utf-8 -*-
"""chicagohealthatlas_utils.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KCG9oIZYj-sI-Zgx0DcFneL_8BRT3HfZ
"""

import requests
import json
from pandas import DataFrame, concat
import logging
import os
import numpy as np

import sys
sys.path.insert(0, os.path.dirname(os.path.realpath(__file__)))

# %%==========================================================
# Ground work
# ============================================================

APIURL = 'https://api.chicagohealthatlas.org/api/v1/'
logger = logging.getLogger()

# %%==========================================================
# Core methods
# ============================================================

def printNlog(msg, level='info'):
  print(msg)
  if level == 'info': 
    logger.info(msg)
  elif level == 'error': 
    logger.error(msg)
  else:
    pass

# %%==========================================================

def get_dict_from_url(urlAppendStr):
  """get JSON response and convert to dict"""
  resp = requests.get(APIURL + urlAppendStr)
  return json.loads(resp.content)  

# %%==========================================================

def parse_list_of_dicts_to_df(list_of_dicts, keep_keys, index_key=None):
  """parse list of dicts into easy to use dataframe"""
  
  df = DataFrame()
  for Dict in list_of_dicts:
    for k in keep_keys: 
      if index_key is None:
        idx = df.shape[0]
      else: 
        idx = Dict[index_key]
      df.loc[idx, k] = Dict[k]
  return df

# %%==========================================================

# %%==========================================================
# Getting global information
# ============================================================

def get_places(savepath=None):
  """get community areas and zip codes df"""

  # get list of places
  places_dict = get_dict_from_url('places')

  # parse community areas into a nice table
  community_areas_df = parse_list_of_dicts_to_df(
      list_of_dicts=places_dict['community_areas'], 
      keep_keys=['geo_type', 'name', 'part'], 
      index_key='slug')

  # parse zip codes into a nice table
  zip_codes_df = parse_list_of_dicts_to_df(
      list_of_dicts=places_dict['zip_codes'], 
      keep_keys=['geo_type', 'id', 'name', 
                 'adjacent_zips', 'adjacent_community_areas'], 
      index_key='slug')
  
  if savepath is not None:
    community_areas_df.to_csv(savepath + 'community_areas_df.csv')
    zip_codes_df.to_csv(savepath + 'zip_codes_df.csv')
    
  return community_areas_df, zip_codes_df

# %%==========================================================

def get_topics(savepath=None):
  """get topics df"""

  # get list of topics
  topics_dict = get_dict_from_url('topics')

  # parse topics into a nice table
  topics_df = parse_list_of_dicts_to_df(
      list_of_dicts=topics_dict, keep_keys=['id', 'name'], index_key='slug')
  
  if savepath is not None:
    topics_df.to_csv(savepath + 'topics_df.csv')
    
  return topics_df

# %%==========================================================

def get_topic_subCategories(savepath=None):
  """parse topic sub-categories into a nice table"""
  
  # get list of topics
  topics_dict = get_dict_from_url('topics')
  
  topic_subCategories_df = DataFrame()

  for topicDict in topics_dict:
    # get details for subcategory
    df = parse_list_of_dicts_to_df(
      list_of_dicts=topicDict['sub_categories'], 
        keep_keys=['id', 'name'], index_key='slug')
    # add details about parent category
    for cn in ['slug',]:
      df.loc[:, 'topic-'+cn] = topicDict[cn]

    # concat with main
    topic_subCategories_df = concat((topic_subCategories_df, df), axis=0)
    
  if savepath is not None:
    topic_subCategories_df.to_csv(savepath + 'topic_subCategories_df.csv')
    
  return topic_subCategories_df

# %%==========================================================

def get_indicators(savepath=None):
  """parse indicators into a nice table"""
  
  # get list of topics
  topics_dict = get_dict_from_url('topics')
  
  indicators_df = DataFrame()

  for topicDict in topics_dict:
    for subcategoryDict in topicDict['sub_categories']:
      # get details for subcategory
      df = parse_list_of_dicts_to_df(
        list_of_dicts=subcategoryDict['indicators'], 
          keep_keys=['id', 'name', 'sub_category_id'], 
          index_key='slug')
      # add details about parent sub-category & category
      for cn in ['slug',]:
        df.loc[:, 'subcategory-'+cn] = subcategoryDict[cn]
        df.loc[:, 'topic-'+cn] = topicDict[cn]
      # concat with main
      indicators_df = concat((indicators_df, df), axis=0)  
      
  if savepath is not None:
    indicators_df.to_csv(savepath + 'indicators_df.csv')
    
  return indicators_df

# %%==========================================================

# %%==========================================================
# Key method to get final tables of interest
# ============================================================

def get_summary_tables(
        INDICATOR_LIST, GEO_LIST, savepath_yearly, savepath_recent):
  """parse indicators and areas into a set of summary tables
  
  Arguments:
    * INDICATOR_LIST - list of indicator slugs
    * GEO_LIST - list of community area of zip slugs
   
  Returns:
    Dict of pandas dataframes
  """
  
  metricnames = [
    'number', 'percent', 
    'cum_number', 'crude_rate',
    'weight_number', 'weight_percent', 
  ]
  
  # This will hold most recent data
  dict_of_dfs = dict()
  for kname in metricnames:
      dict_of_dfs['MOST-RECENT_%s' % kname] = DataFrame(
              index=INDICATOR_LIST, columns=GEO_LIST)
  
  # now loop through indicators and places
  for indicator_slug in INDICATOR_LIST:
    for geo_slug in GEO_LIST:
      
      printNlog(" Getting data for: %s: %s" % (indicator_slug, geo_slug))
      
      # get detailed data for indicator and community area
      data_dict = get_dict_from_url('topic_info/%s/%s' % (
          geo_slug, indicator_slug))
      
      for kname in metricnames:
          
        recent = 0 # most recent year for this metric
        
        for tDict in data_dict['area_data']:
          
          try:
            # Identify and/or init dataframe
            dfname = "from-%d-to-%d_%s" % (
                tDict['year_from'], tDict['year_to'], kname)
            if dfname not in dict_of_dfs.keys():
              dict_of_dfs[dfname] = DataFrame(
                      index=INDICATOR_LIST, columns=GEO_LIST)
            
            if (kname in tDict.keys()) and (tDict[kname] is not None):
              
              # Now add data about this time period
              dict_of_dfs[dfname].loc[
                indicator_slug, geo_slug] = tDict[kname]
              
              # Add to most recent if this is it
              if (np.isfinite(tDict[kname])) and (tDict['year_to'] > recent):
                recent = tDict['year_to'] 
                dict_of_dfs['MOST-RECENT_%s' % kname].loc[
                  indicator_slug, geo_slug] = tDict[kname]
            else:
              #printNlog("  %s not in keys or is None!" % kname, level='error')
              pass
            
          except Exception as e:
            printNlog(e, level='error')
      
      # now save -- overwrite  
      for k in dict_of_dfs.keys():
        savepath = savepath_yearly if k.startswith('from') else savepath_recent
        dict_of_dfs[k].to_csv(savepath + k + ".csv")
          
  return dict_of_dfs

# %%==========================================================

# %%==========================================================
# Overall workflow
# ============================================================

def main():
  """run full pipeline"""
  
  import configs as cf
  
  # sanity checks
  assert cf.SAVEPATH is not None, "SAVEPATH is not specified"
    
  if cf.INDICATOR_LIST is None:
    assert cf.GET_INDICATORS, "GET_INDICATORS MUST be True, otherwise specify INDICATOR_LIST"
      
  if cf.GEO_LIST is None:
    assert cf.GET_PLACES, "GET_INDICATORS MUST be True, otherwise specify GEO_LIST"
  
  # configure logger
  logging.basicConfig(filename=cf.SAVEPATH + 'runLog.log', level=logging.INFO)
  #logging.basicConfig(filename=cf.SAVEPATH + 'runLog.log', level=logging.DEBUG)
  printNlog("STARTED.")
  
  SAVEPATHS = {
    'GENERAL': cf.SAVEPATH + 'General/',
    'YEARLY': cf.SAVEPATH + 'Yearly/',
    'RECENT': cf.SAVEPATH + 'MostRecent/',
  }
  for _, folder in SAVEPATHS.items():
    try:
      printNlog("Creating %s" % folder)
      os.mkdir(folder)
    except FileExistsError:
      pass
  
  # Global stuff
  if cf.GET_PLACES:
    printNlog("Getting places tables ...")
    community_areas_df, _ = get_places(savepath=SAVEPATHS['GENERAL'])
    
  if cf.GET_TOPICS:
    printNlog("Getting topics tables ...")
    get_topics(savepath=SAVEPATHS['GENERAL'])
    
  if cf.GET_TOPIC_SUBCATEGORIES:
    printNlog("Getting topic subcategories tables ...")
    get_topic_subCategories(savepath=SAVEPATHS['GENERAL'])
    
  if cf.GET_INDICATORS:
    printNlog("Getting indicators tables ...")
    indicators_df = get_indicators(savepath=SAVEPATHS['GENERAL'])
  
  # the main stuff
  if cf.GET_SUMMARY_TABLES:
  
    printNlog("Getting summary tables ...")
    
    if cf.INDICATOR_LIST is None:
        INDICATOR_LIST = list(indicators_df.index)
    else:
        INDICATOR_LIST = cf.INDICATOR_LIST
    
    if cf.GEO_LIST is None:
        GEO_LIST = list(community_areas_df.index)
    else:
        GEO_LIST = cf.GEO_LIST
    
    # now get the tables
    get_summary_tables(
      INDICATOR_LIST=INDICATOR_LIST, GEO_LIST=GEO_LIST, 
      savepath_yearly=SAVEPATHS['YEARLY'], savepath_recent=SAVEPATHS['RECENT'])
        
  printNlog("DONE.")

# %%==========================================================
# Overall workflow
# ============================================================

if __name__ == '__main__':
    main()